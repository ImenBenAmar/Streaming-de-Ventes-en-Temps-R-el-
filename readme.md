# ğŸš€ Streaming de Ventes en Temps RÃ©el
### Architecture Lakehouse avec Kafka + Spark Structured Streaming + Delta Lake

[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white)](https://kafka.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta%20Lake-00ADD4?style=for-the-badge&logo=databricks&logoColor=white)](https://delta.io/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)

> **Un pipeline de donnÃ©es moderne pour l'analyse de ventes en temps rÃ©el avec architecture Lakehouse multicouche**

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#-vue-densemble)
- [Architecture](#-architecture)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Technologies](#-technologies)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [RÃ©sultats](#-rÃ©sultats)
- [DÃ©fis et Solutions](#-dÃ©fis-et-solutions)
- [AmÃ©liorations Futures](#-amÃ©liorations-futures)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente une **architecture Lakehouse complÃ¨te** pour le traitement et l'analyse de flux de ventes en temps rÃ©el. Il simule un systÃ¨me e-commerce gÃ©nÃ©rant des transactions continues, les traite via Spark Structured Streaming, et les stocke dans Delta Lake avec une architecture Bronze-Silver pour garantir qualitÃ© et traÃ§abilitÃ© des donnÃ©es.

### Objectifs PÃ©dagogiques

- âœ… Simuler un **flux de ventes rÃ©aliste** avec Kafka Producer
- âœ… Consommer et transformer des donnÃ©es avec **Spark Structured Streaming**
- âœ… ImplÃ©menter un **Lakehouse** avec Delta Lake (ACID, Time Travel)
- âœ… Mettre en place une architecture **Bronze â†’ Silver** (Raw â†’ Enriched)
- âœ… CrÃ©er un **dashboard temps rÃ©el** pour le monitoring business
- âœ… Garantir la **rÃ©silience** et la **scalabilitÃ©** du pipeline

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[ğŸ² Producteur Kafka<br/>producer_ventes.py] -->|Messages JSON| B(ğŸ“¨ Kafka Topic<br/>ventes_stream)
    B -->|Stream| C[âš¡ Spark Structured Streaming<br/>spark_streaming_delta.py]
    C -->|Raw Data| D[(ğŸ¥‰ Delta Lake Bronze<br/>DonnÃ©es Brutes)]
    C -->|Enrichissement| E[(ğŸ¥ˆ Delta Lake Silver<br/>DonnÃ©es Enrichies)]
    E -->|SQL Queries| F[ğŸ“Š Dashboard Temps RÃ©el<br/>dashboard_query.py]
    E -->|Export| G[ğŸ“ˆ BI Tools<br/>Power BI, Tableau]
    
    style A fill:#ff6b6b
    style B fill:#4ecdc4
    style C fill:#45b7d1
    style D fill:#cd7f32
    style E fill:#c0c0c0
    style F fill:#95e1d3
    style G fill:#f38181
```

### Flux de DonnÃ©es DÃ©taillÃ©

1. **Production** : GÃ©nÃ©ration de ventes simulÃ©es toutes les 2 secondes
2. **Ingestion** : Kafka stocke les Ã©vÃ©nements dans le topic `ventes_stream`
3. **Streaming** : Spark lit le stream Kafka en continu
4. **Bronze Layer** : Stockage des donnÃ©es brutes (format original)
5. **Silver Layer** : Enrichissement avec calculs mÃ©tiers (total_depense)
6. **Visualisation** : Dashboard SQL avec agrÃ©gations par pays/segment

---

## âœ¨ FonctionnalitÃ©s

### ğŸ² GÃ©nÃ©rateur de DonnÃ©es RÃ©aliste
- Simulation de 5 produits (Ordinateur, Smartphone, Tablette, Ã‰couteurs, Clavier)
- 5 pays europÃ©ens (France, Allemagne, Italie, Espagne, UK)
- 3 segments clients (Particulier, Entreprise, Ã‰ducation)
- Timestamps prÃ©cis pour chaque transaction
- QuantitÃ©s et prix variables

### âš¡ Traitement Temps RÃ©el
- **Lecture continue** depuis Kafka
- **Parsing JSON** avec schÃ©ma validÃ©
- **Enrichissement** automatique (calcul total_depense)
- **Checkpointing** pour la rÃ©silience
- **Exactly-once semantics** avec Delta Lake

### ğŸ—„ï¸ Architecture Lakehouse

#### Bronze Layer (DonnÃ©es Brutes)
- Conservation de **toutes les donnÃ©es originales**
- Format Delta pour ACID compliance
- Time Travel activÃ© (rollback possible)
- Checkpoint pour reprise sur erreur

#### Silver Layer (DonnÃ©es Enrichies)
- **Calcul du total_depense** (quantitÃ© Ã— prix_unitaire)
- **Timestamp de traitement** ajoutÃ©
- DonnÃ©es nettoyÃ©es et validÃ©es
- PrÃªtes pour l'analyse business

### ğŸ“Š Dashboard Temps RÃ©el
- RafraÃ®chissement automatique toutes les 30 secondes
- **AgrÃ©gation par pays et segment**
- Tri par chiffre d'affaires dÃ©croissant
- Affichage des 15 meilleures combinaisons

---

## ğŸ› ï¸ Technologies

| Technologie | Version | RÃ´le |
|------------|---------|------|
| **Apache Kafka** | 3.x | Message Broker pour le streaming |
| **Apache Spark** | 3.5+ | Traitement distribuÃ© en temps rÃ©el |
| **Delta Lake** | 3.x | Stockage ACID avec Time Travel |
| **Python** | 3.8+ | Langage de dÃ©veloppement |
| **kafka-python** | 2.x | Client Kafka Python |
| **PySpark** | 3.5+ | API Spark pour Python |

---

## ğŸ“¦ Installation

### PrÃ©requis

- Java JDK 11+ (pour Spark et Kafka)
- Python 3.8+
- 8 GB RAM minimum recommandÃ©

### 1ï¸âƒ£ Installation de Kafka

**macOS (Homebrew)**
```bash
brew install kafka
```

**Linux/Windows**
```bash
# TÃ©lÃ©charger depuis https://kafka.apache.org/downloads
wget https://downloads.apache.org/kafka/3.6.0/kafka_2.13-3.6.0.tgz
tar -xzf kafka_2.13-3.6.0.tgz
cd kafka_2.13-3.6.0
```

### 2ï¸âƒ£ Installation de Spark

```bash
# TÃ©lÃ©charger Spark depuis https://spark.apache.org/downloads.html
wget https://dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz
tar -xzf spark-3.5.0-bin-hadoop3.tgz

# Configurer les variables d'environnement
export SPARK_HOME=/path/to/spark-3.5.0-bin-hadoop3
export PATH=$SPARK_HOME/bin:$PATH
export PYSPARK_PYTHON=python3
```

### 3ï¸âƒ£ Installation des Packages Python

```bash
# CrÃ©er un environnement virtuel (recommandÃ©)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install kafka-python pyspark delta-spark
```

### 4ï¸âƒ£ TÃ©lÃ©charger les JARs nÃ©cessaires

<<<<<<< HEAD
```bash
# Delta Lake
wget https://repo1.maven.org/maven2/io/delta/delta-core_2.12/2.4.0/delta-core_2.12-2.4.0.jar

# Kafka pour Spark
wget https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar
```

---

## ğŸš€ Utilisation

### Ã‰tape 1 : DÃ©marrer Kafka

```bash
# Terminal 1 : DÃ©marrer ZooKeeper
zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties

# Terminal 2 : DÃ©marrer Kafka
kafka-server-start /usr/local/etc/kafka/server.properties

# Terminal 3 : CrÃ©er le topic
kafka-topics --create --topic ventes_stream --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

### Ã‰tape 2 : Lancer le Producteur

```bash
# Terminal 4
python producer_ventes.py
```

**Sortie attendue :**
```
Vente envoyÃ©e : {'id_vente': 1234, 'produit': 'Smartphone', 'quantite': 3, 'prix_unitaire': 599.99, 'pays': 'France', 'segment': 'Particulier', 'timestamp': '2025-12-12T10:30:45.123456'}
Vente envoyÃ©e : {'id_vente': 5678, 'produit': 'Ordinateur', 'quantite': 1, 'prix_unitaire': 899.50, 'pays': 'Allemagne', 'segment': 'Entreprise', 'timestamp': '2025-12-12T10:30:47.654321'}
```

### Ã‰tape 3 : Lancer le Streaming Spark

```bash
# Terminal 5
spark-submit \
  --packages io.delta:delta-core_2.12:2.4.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  spark_streaming_delta.py
```

**Logs attendus :**
```
Starting Spark Structured Streaming...
Bronze checkpoint: C:/tmp/delta/bronze/checkpoint
Silver checkpoint: C:/tmp/delta/silver/checkpoint
Processing batch 1...
Processing batch 2...
```

### Ã‰tape 4 : Lancer le Dashboard

```bash
# Terminal 6
python dashboard_query.py
```

**Sortie dashboard :**
```
DASHBOARD EN TEMPS RÃ‰EL - CA PAR PAYS/SEGMENT
================================================================================

MISE Ã€ JOUR : 10:35:22
--------------------------------------------------------------------------------
+----------+-----------+-----------------+
|pays      |segment    |ca_total         |
+----------+-----------+-----------------+
|France    |Entreprise |15678.45         |
|Allemagne |Particulier|12345.90         |
|Espagne   |Ã‰ducation  |9876.20          |
+----------+-----------+-----------------+
```

---

## ğŸ“ Structure du Projet

```
streaming-ventes-temps-reel/
â”‚
â”œâ”€â”€ ğŸ“„ producer_ventes.py          # GÃ©nÃ©rateur de ventes simulÃ©es
â”œâ”€â”€ ğŸ“„ spark_streaming_delta.py    # Pipeline Spark Streaming
â”œâ”€â”€ ğŸ“„ dashboard_query.py          # Dashboard temps rÃ©el
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ¥‰ bronze/                 # Couche Bronze (raw)
â”‚   â”‚   â”œâ”€â”€ ventes/                # Tables Delta
â”‚   â”‚   â””â”€â”€ checkpoint/            # Points de reprise
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ¥ˆ silver/                 # Couche Silver (enriched)
â”‚       â”œâ”€â”€ ventes_agg/            # Tables Delta enrichies
â”‚       â””â”€â”€ checkpoint/            # Points de reprise
â”‚
â”œâ”€â”€ ğŸ“‚ images/
â”‚   â”œâ”€â”€ demo.mp4                   # VidÃ©o de dÃ©monstration
â”‚   â”œâ”€â”€ sample_data.png            # Exemple de donnÃ©es
â”‚   â”œâ”€â”€ dashbord.png               # Dashboard principal
â”‚   â””â”€â”€ dashbord_sql.png           # RequÃªtes SQL
â”‚
â””â”€â”€ ğŸ“„ README.md                   # Documentation (ce fichier)
```

---

## ğŸ“Š RÃ©sultats

### ğŸ¬ DÃ©monstration VidÃ©o

[â–¶ï¸ Voir la dÃ©mo complÃ¨te (demo.mp4)](./images/dashbord_temp_relle.mp4)

### ğŸ“¸ Captures d'Ã‰cran

#### Exemple de DonnÃ©es StreamÃ©es
![Sample Data](./images/sample_data.png)
*Flux de ventes en temps rÃ©el avec horodatage*

#### Dashboard Temps RÃ©el
![Dashboard](./images/dashbord.png)
*AgrÃ©gation automatique par pays et segment*

#### RequÃªtes SQL sur Delta Lake
![Dashboard SQL](./images/dashbord_sql.png)
*Analyse interactive avec Spark SQL*

### ğŸ“ˆ MÃ©triques de Performance

- **Latence de traitement** : < 3 secondes end-to-end
- **DÃ©bit** : 30 transactions/minute (configurable)
- **Taille des batches** : Micro-batches de 2 secondes
- **Stockage Delta** : Compression automatique + versioning

---

## ğŸ”§ DÃ©fis et Solutions

### DÃ©fi 1 : Gestion des Chemins Windows
**ProblÃ¨me** : Erreurs de parsing des chemins sur Windows  
**Solution** : Utilisation de `r"C:/tmp/..."` (raw strings) et normalisation des slashes

### DÃ©fi 2 : Checkpointing Kafka
**ProblÃ¨me** : Perte de donnÃ©es en cas de crash  
**Solution** : Activation des checkpoints Spark + `startingOffsets="earliest"`

### DÃ©fi 3 : Performances du Dashboard
**ProblÃ¨me** : Lectures rÃ©pÃ©tÃ©es coÃ»teuses  
**Solution** : Caching Spark + agrÃ©gations prÃ©-calculÃ©es dans Silver

### DÃ©fi 4 : CompatibilitÃ© des Versions
**ProblÃ¨me** : IncompatibilitÃ©s Spark/Delta/Kafka  
**Solution** : Utilisation de packages Maven coordonnÃ©s (version 3.5.0 partout)

---

## ğŸš€ AmÃ©liorations Futures

### Court Terme
- [ ] Ajout de **schemas evolution** pour Delta Lake
- [ ] ImplÃ©mentation de **alertes** sur seuils mÃ©tier
- [ ] Dashboard **Grafana/Kibana** pour monitoring avancÃ©
- [ ] Tests unitaires avec **pytest** + mocking

### Moyen Terme
- [ ] Migration vers **Kafka Streams** pour enrichissement cÃ´tÃ© streaming
- [ ] Ajout d'une couche **Gold** (star schema pour BI)
- [ ] **CI/CD pipeline** avec GitHub Actions
- [ ] **Containerisation** Docker + Kubernetes

### Long Terme
- [ ] Passage Ã  **Azure Event Hubs** ou **AWS Kinesis**
- [ ] IntÃ©gration **MLflow** pour scoring temps rÃ©el
- [ ] **Data Quality** checks automatisÃ©s (Great Expectations)
- [ ] **Multi-tenant** architecture

---

## ğŸ“š Ressources et Documentation

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spark Structured Streaming Guide](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Delta Lake Documentation](https://docs.delta.io/latest/index.html)
- [Lakehouse Architecture (Databricks)](https://www.databricks.com/glossary/data-lakehouse)

---

## ğŸ‘¥ Contribution

Les contributions sont les bienvenues ! Merci de :

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/amelioration`)
3. Commit vos changements (`git commit -m 'Ajout fonctionnalitÃ© X'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

---

## ğŸ“„ Licence

Ce projet est Ã  usage **Ã©ducatif** dans le cadre du TP 3.  
Libre d'utilisation avec attribution.

---

## ğŸ“§ Contact

Pour toute question ou suggestion :
- ğŸ“© Email : [imen.bnamar@gmail.com]
- ğŸ’¼ LinkedIn : [https://www.linkedin.com/in/imen-benamar-616079212/]
- ğŸ™ GitHub : [@ImenBenAmar]


---

<div align="center">

**â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile ! â­**

Fait avec â¤ï¸ et beaucoup de â˜•

</div>
